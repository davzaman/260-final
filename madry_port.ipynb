{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data as td\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "#         self.x_input = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "#         self.y_input = tf.placeholder(tf.int64, shape = [None])\n",
    "#         self.x_image = tf.reshape(self.x_input, [-1, 28, 28, 1])\n",
    "\n",
    "        # first convolutional layer\n",
    "        # In channels, out channels, square kernel size, stride padding\n",
    "        self.conv1 = nn.Conv2d(1,32,5,1,1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32,64,5,1,1)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        # first fully connected layer\n",
    "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
    "\n",
    "        # output layer\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "        \n",
    "#         y_xent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#             labels=self.y_input, logits=self.pre_softmax)\n",
    "        self.xent = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#         self.y_pred = tf.argmax(self.pre_softmax, 1)\n",
    "#         correct_prediction = tf.equal(self.y_pred, self.y_input)\n",
    "#         self.num_correct = tf.reduce_sum(tf.cast(correct_prediction, tf.int64))\n",
    "#         self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinfPGDAttack:\n",
    "    def __init__(self, model, cost, epsilon, k, a, random_start, loss_func):\n",
    "        \"\"\"Attack parameter initialization. The attack performs k steps of\n",
    "           size a, while always staying within epsilon from the initial\n",
    "           point.\"\"\"\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.k = k\n",
    "        self.a = a\n",
    "        self.rand = random_start\n",
    "\n",
    "        if loss_func == 'xent':\n",
    "            loss = model.xent\n",
    "        elif loss_func == 'cw':\n",
    "            label_mask = tf.one_hot(model.y_input,\n",
    "                                  10,\n",
    "                                  on_value=1.0,\n",
    "                                  off_value=0.0,\n",
    "                                  dtype=tf.float32)\n",
    "            correct_logit = tf.reduce_sum(label_mask * model.pre_softmax, axis=1)\n",
    "            wrong_logit = tf.reduce_max((1-label_mask) * model.pre_softmax, axis=1)\n",
    "            loss = -tf.nn.relu(correct_logit - wrong_logit + 50)\n",
    "        else:\n",
    "            print('Unknown loss function. Defaulting to cross-entropy')\n",
    "            loss = model.xent\n",
    "\n",
    "        self.grad = tf.gradients(loss, model.x_input)[0]\n",
    "\n",
    "    def perturb(self, x_nat, y, sess):\n",
    "        \"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n",
    "           examples within epsilon of x_nat in l_infinity norm.\"\"\"\n",
    "        if self.rand:\n",
    "            x = x_nat + np.random.uniform(-self.epsilon, self.epsilon, x_nat.shape)\n",
    "        else:\n",
    "            x = np.copy(x_nat)\n",
    "\n",
    "        for i in range(self.k):\n",
    "            grad = sess.run(self.grad, feed_dict={self.model.x_input: x,\n",
    "                                                  self.model.y_input: y})\n",
    "\n",
    "            x += self.a * np.sign(grad)\n",
    "\n",
    "            x = np.clip(x, x_nat - self.epsilon, x_nat + self.epsilon) \n",
    "            x = np.clip(x, 0, 1) # ensure valid pixel range\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
